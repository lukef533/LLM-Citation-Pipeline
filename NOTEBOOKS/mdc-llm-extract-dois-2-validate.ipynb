{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Installs / Imports","metadata":{}},{"cell_type":"code","source":"# Installs\n\n!pip install --no-index --find-links=/kaggle/input/latest-mdc-whls/whls pymupdf transformers accelerate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Imports\n\nimport os \nfrom pathlib import Path\nimport re\nfrom collections import Counter\nimport nltk\n\nimport pandas as pd\nimport numpy as np\n\n# PDF parsing\nimport fitz\n\n# plotting\nimport matplotlib.pyplot as plt\n\n# Sentence tokenizer\nnltk.download('punkt')\nfrom nltk.tokenize import sent_tokenize\n\n# load LLM\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom tqdm.auto import tqdm\nimport torch\n\nimport transformers\ntransformers.logging.set_verbosity_error() # hide non critical warnings \n\n\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T19:09:19.314704Z","iopub.execute_input":"2025-08-05T19:09:19.314932Z","iopub.status.idle":"2025-08-05T19:09:19.415051Z","shell.execute_reply.started":"2025-08-05T19:09:19.314909Z","shell.execute_reply":"2025-08-05T19:09:19.414076Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Filepaths","metadata":{}},{"cell_type":"code","source":"# File paths\n\ntrain_path = '/kaggle/input/make-data-count-finding-data-references/train'\ntrain_pdf_path = '/kaggle/input/make-data-count-finding-data-references/train/PDF'\ntrain_xml_path = '/kaggle/input/make-data-count-finding-data-references/train/XML'\n\ntrain_labels_path = '/kaggle/input/make-data-count-finding-data-references/train_labels.csv'\n\ntest_path = '/kaggle/input/make-data-count-finding-data-references/test'\ntest_pdf_path = '/kaggle/input/make-data-count-finding-data-references/test/PDF'\ntest_xml_path = '/kaggle/input/make-data-count-finding-data-references/test/XML'\n\nsample_submission_path = '/kaggle/input/make-data-count-finding-data-references/sample_submission.csv'\n\ndf_labels = pd.read_csv(train_labels_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T19:09:19.415833Z","iopub.execute_input":"2025-08-05T19:09:19.416046Z","iopub.status.idle":"2025-08-05T19:09:19.427197Z","shell.execute_reply.started":"2025-08-05T19:09:19.416029Z","shell.execute_reply":"2025-08-05T19:09:19.426343Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Split Training / Validation Data","metadata":{}},{"cell_type":"code","source":"# Set your train PDF directory path\ntrain_pdf_path = '/kaggle/input/make-data-count-finding-data-references/train/PDF'\n\n# List all PDF files in the train directory\nall_pdf_files = sorted([f for f in os.listdir(train_pdf_path) if f.endswith('.pdf')])\n\n# Set random seed for reproducibility\nimport random\nrandom.seed(42)\n\n# Split: 80% train, 20% validation (adjust as needed)\nval_percent = 0.2\nn_val = int(len(all_pdf_files) * val_percent)\nval_pdf_files = set(random.sample(all_pdf_files, n_val))\ntrain_pdf_files = [f for f in all_pdf_files if f not in val_pdf_files]\n\nprint(f\"Total PDFs: {len(all_pdf_files)}\")\nprint(f\"Train PDFs: {len(train_pdf_files)}\")\nprint(f\"Validation PDFs: {len(val_pdf_files)}\")\n\n# Optional: Save to files for consistency in future runs\nwith open(\"val_pdf_files.txt\", \"w\") as f:\n    for fname in sorted(val_pdf_files):\n        f.write(f\"{fname}\\n\")\nwith open(\"train_pdf_files.txt\", \"w\") as f:\n    for fname in sorted(train_pdf_files):\n        f.write(f\"{fname}\\n\")\n\n\n\n# train + validate labels\ndf_train_labels = df_labels[df_labels['article_id'].isin([f.replace('.pdf','') for f in train_pdf_files])].reset_index(drop=True)\ndf_val_labels = df_labels[df_labels['article_id'].isin([f.replace('.pdf','') for f in val_pdf_files])].reset_index(drop=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Regex Extraction","metadata":{}},{"cell_type":"code","source":"def extract_contexts(pdf_directory, file_list, verbose=True):\n    import os\n    from tqdm.auto import tqdm\n    import fitz  # PyMuPDF\n    import re\n\n    chunks = []\n    chunks2 = []\n    text_span_len = 500\n\n    # --- BEST PRACTICE REGEX PATTERNS ---\n    re_doi = re.compile(r\"10\\.\\d{4,9}/[-._;()/:A-Z0-9]+\", re.IGNORECASE)\n    re_gsr = re.compile(r\"GSE\\d+|SR[APRX]\\d+|PRJ[NAED][A-Z]?\\d+|E-[A-Z]+-\\d+\", re.IGNORECASE)\n    re_ipe = re.compile(r\"IPR\\d{6}|PF\\d{5}|EMPIAR-\\d{5}|EMD-\\d{4,5}\", re.IGNORECASE)\n    re_c = re.compile(r\"CHEMBL\\d+|CVCL_[A-Z0-9]{4}|CID:\\d+\", re.IGNORECASE)\n    re_e = re.compile(r\"ENS[A-Z]{0,6}[GT]\\d{11}|ENSG\\d{11}\", re.IGNORECASE)\n    re_r = re.compile(r\"N[MC]_\\d+(?:\\.\\d+)?|rs\\d+|XM_\\d+|XP_\\d+\", re.IGNORECASE)\n    re_u = re.compile(r\"(?:uniprot:)?(?:[OPQ][0-9][A-Z0-9]{3}[0-9]|[A-NR-Z][0-9][A-Z][A-Z0-9]{2}[0-9])\", re.IGNORECASE)\n    re_g = re.compile(r\"EPI(?:_ISL_)?\\d+|GISAID\", re.IGNORECASE)\n    re_p = re.compile(r\"PXD\\d{6}|SAM[ND]\\d+|ERR\\d+|DRR\\d+|MSV\\d+\", re.IGNORECASE)\n    re_geo = re.compile(r\"GDS\\d+|GPL\\d+|GSM\\d+\", re.IGNORECASE)\n    re_arrayexpress = re.compile(r\"E-[A-Z]+-\\d+\", re.IGNORECASE)\n\n    relist = [\n        re_gsr, re_ipe, re_c, re_e, re_r, re_u, re_g, re_p, re_geo, re_arrayexpress\n    ]\n\n    ids = []\n\n    def remove_references_section(text):\n        lines = text.split('\\n')\n        cut_index = -1\n        for i in range(len(lines) - 1, max(0, int(len(lines) * 0.3)), -1):\n            line = lines[i].strip()\n            obvious_patterns = [\n                r'^REFERENCES?$', r'^\\d+\\.?\\s+REFERENCES?$', r'^\\d+\\.?\\s+References?$',\n                r'^References?:?$', r'^BIBLIOGRAPHY$', r'^\\d+\\.?\\s+BIBLIOGRAPHY$',\n                r'^\\d+\\.?\\s+Bibliography$', r'^Bibliography:?$', r'^Literature\\s+Cited$', r'^Works\\s+Cited$'\n            ]\n            if any(re.match(pattern, line, re.IGNORECASE) for pattern in obvious_patterns):\n                following_lines = lines[i+1:i+4]\n                has_citations = False\n                for follow_line in following_lines:\n                    if follow_line.strip():\n                        if (re.search(r'\\(\\d{4}\\)', follow_line)\n                            or re.search(r'\\d{4}\\.', follow_line)\n                            or 'doi:' in follow_line.lower()\n                            or ' et al' in follow_line.lower()):\n                            has_citations = True\n                            break\n                if has_citations or i >= len(lines) - 3:\n                    cut_index = i\n                    break\n        if cut_index != -1:\n            return '\\n'.join(lines[:cut_index]).strip()\n        return text.strip()\n\n    empty_or_error_pdfs = 0\n    short_text_pdfs = 0\n    total_files = 0\n\n    if verbose:\n        print(f\"Found {len(file_list)} PDF files in directory:\")\n        for fn in file_list:\n            print(f\"  {fn}\")\n\n    for filename in tqdm(file_list, total=len(file_list)):\n        if filename.endswith(\".pdf\"):\n            pdf_path = os.path.join(pdf_directory, filename)\n            article_id = filename.split(\".pdf\")[0]\n            total_files += 1\n\n            try:\n                doc = fitz.open(pdf_path)\n                n_pages = len(doc)\n                text = \"\"\n                for page in doc:\n                    page_text = page.get_text()\n                    text += page_text + \"\\n\"\n                doc.close()\n                if verbose:\n                    print(f\"{filename}: {n_pages} pages, {len(text)} chars\")\n            except Exception as e:\n                if verbose:\n                    print(f\"Could not process {filename}: {e}\")\n                empty_or_error_pdfs += 1\n                continue\n\n            if len(text.strip()) < 800:\n                short_text_pdfs += 1\n                if verbose:\n                    print(f\"  [{filename}] WARNING: very short text: {len(text)} chars\")\n                    print(f\"  Sample: {text[:200]}\")\n            text = remove_references_section(text)\n\n            doi_chunk_count = 0\n            doi_matches = re_doi.finditer(text)\n            for match in doi_matches:\n                if match.group() in article_id: continue\n                doi_chunk_count += 1\n                chunk = text[max(0, match.start() - text_span_len): match.start() + text_span_len]\n                chunks.append((article_id, chunk))\n            if verbose:\n                print(f\"  -> Found {doi_chunk_count} DOI matches (before filtering).\")\n\n            acc_chunk_count = 0\n            for rr in relist:\n                matches = rr.finditer(text)\n                for match in matches:\n                    ids.append(match.group())\n                    acc_chunk_count += 1\n                    chunk = text[max(0, match.start() - text_span_len): match.start() + text_span_len]\n                    chunks2.append((article_id, chunk))\n            if verbose:\n                print(f\"  -> Found {acc_chunk_count} accession/other ID matches.\")\n\n    if verbose:\n        print(\"=\"*60)\n        print(f\"DOI chunks (contexts): {len(chunks)}\")\n        print(f\"Accession/other ID chunks: {len(chunks2)}\")\n        print(f\"Skipped or errored PDFs: {empty_or_error_pdfs}\")\n        print(f\"Short (<800 chars) but readable PDFs: {short_text_pdfs}\")\n        print(f\"Total processed PDFs: {total_files}\")\n        print(\"=\"*60)\n        if len(chunks):\n            print(\"Sample DOI extraction chunk (first 1):\\n\", chunks[0])\n        if len(chunks2):\n            print(\"Sample accession extraction chunk (first 1):\\n\", chunks2[0])\n\n    return chunks, chunks2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T19:10:32.020013Z","iopub.execute_input":"2025-08-05T19:10:32.020258Z","iopub.status.idle":"2025-08-05T19:10:32.037943Z","shell.execute_reply.started":"2025-08-05T19:10:32.020238Z","shell.execute_reply":"2025-08-05T19:10:32.037050Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# After your splitting code:\n\ntrain_chunks, train_chunks2 = extract_contexts(train_pdf_path, train_pdf_files, verbose=False)\nval_chunks, val_chunks2 = extract_contexts(train_pdf_path, list(val_pdf_files), verbose=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T19:10:32.038813Z","iopub.execute_input":"2025-08-05T19:10:32.039147Z","iopub.status.idle":"2025-08-05T19:11:44.474827Z","shell.execute_reply.started":"2025-08-05T19:10:32.039107Z","shell.execute_reply":"2025-08-05T19:11:44.473966Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/420 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a7bdf5a87ce47169b984e0e29563d6f"}},"metadata":{}},{"name":"stdout","text":"MuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\nMuPDF error: unsupported error: cannot create appearance stream for  annotations\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/104 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16527629c63a4504b5db0a6419ffb4ff"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# --------- DIAGNOSTICS: Cell 1 (Context Extraction -- Training Data) ---------\n\n\nprint(f\"\\n[Cell 1 DIAGNOSTICS] (TRAIN) Chunks extracted: {len(train_chunks)}\")\nprint(f\"[Cell 1 DIAGNOSTICS] (TRAIN) Other ID (accession) chunks: {len(train_chunks2)}\")\n\nif len(train_chunks) >= 5:\n    print(\"[Cell 1 DIAGNOSTICS] (TRAIN) Sample extracted chunk:\")\n    for i in range(5):\n        print(f\"  Article: {train_chunks[i][0]} | Context preview: {train_chunks[i][1][:100]}...\")\n\nprint(f\"\\n[Cell 1 DIAGNOSTICS] (TRAIN) Using {len(train_chunks)} random chunks from {len(train_chunks)} total (chunks).\")\n\n# Histogram of context lengths\nlens = [len(c[1]) for c in train_chunks]\nif lens:\n    print(f\"[Cell 1 DIAGNOSTICS] (TRAIN) Context window length stats: min={min(lens)}, max={max(lens)}, mean={sum(lens)/len(lens):.1f}\")\n    plt.hist(lens, bins=10)\n    plt.title(\"Distribution of context_window lengths (TRAIN)\")\n    plt.xlabel(\"Context length (characters)\")\n    plt.ylabel(\"Count\")\n    plt.show()\nelse:\n    print(\"[Cell 1 DIAGNOSTICS] (TRAIN) No context window lengths available.\")\n\n# Duplicated chunk check\ndups = len(train_chunks) - len(set([str(x) for x in train_chunks]))\nprint(f\"[Cell 1 DIAGNOSTICS] (TRAIN) Duplicate (article_id, context) pairs in train_chunks: {dups}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T19:11:44.476128Z","iopub.execute_input":"2025-08-05T19:11:44.476424Z","iopub.status.idle":"2025-08-05T19:11:44.717859Z","shell.execute_reply.started":"2025-08-05T19:11:44.476391Z","shell.execute_reply":"2025-08-05T19:11:44.717110Z"}},"outputs":[{"name":"stdout","text":"\n[Cell 1 DIAGNOSTICS] (TRAIN) Chunks extracted: 4901\n[Cell 1 DIAGNOSTICS] (TRAIN) Other ID (accession) chunks: 2321\n[Cell 1 DIAGNOSTICS] (TRAIN) Sample extracted chunk:\n  Article: 10.1002_2017jc013030 | Context preview: RESEARCH ARTICLE\n10.1002/2017JC013030\nAssessing the Variability in the Relationship Between the\nPart...\n  Article: 10.1002_2017jc013030 | Context preview: ing Information S2\n\u0002 Supporting Information S3\n\u0002 Table S1\n\u0002 Table S2\n\u0002 Table S3\nCorrespondence to:\nM...\n  Article: 10.1002_2017jc013030 | Context preview: s (Table 1), fol-\nlowing the bioregions presented in Organelli et al. (2017a), except for the Easter...\n  Article: 10.1002_2017jc013030 | Context preview: \n2\nNorth Atlantic Western Subtropical Gyre\nWNASTG\n12\n2\nSouth Atlantic South Subtropical Gyre\nSSASTG\n...\n  Article: 10.1002_2017jc013030 | Context preview: -Chla relationship. Overall, those minor changes have little impact on the\nFigure 1. Geographical lo...\n\n[Cell 1 DIAGNOSTICS] (TRAIN) Using 4901 random chunks from 4901 total (chunks).\n[Cell 1 DIAGNOSTICS] (TRAIN) Context window length stats: min=515, max=1000, mean=978.9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"[Cell 1 DIAGNOSTICS] (TRAIN) Duplicate (article_id, context) pairs in train_chunks: 0\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"## Load LLM","metadata":{}},{"cell_type":"code","source":"# Load LLM\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nMODEL_PATH = \"/kaggle/input/qwen2/transformers/qwen2-1.5b-instruct/1\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_PATH,\n    device_map=\"auto\",\n    torch_dtype=\"auto\",\n    local_files_only=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T19:11:44.718588Z","iopub.execute_input":"2025-08-05T19:11:44.718814Z","iopub.status.idle":"2025-08-05T19:11:46.755512Z","shell.execute_reply.started":"2025-08-05T19:11:44.718796Z","shell.execute_reply":"2025-08-05T19:11:46.754907Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"## LLM Extract DOIs","metadata":{}},{"cell_type":"code","source":"def run_llm_doi_extraction(chunks, model, tokenizer, max_new_tokens=64, show_samples=5):\n    \"\"\"\n    Run LLM DOI extraction and validation on a list of (article_id, context_window) pairs.\n\n    Args:\n        chunks: list of (article_id, context_window) tuples.\n        model: HuggingFace (or similar) LLM.\n        tokenizer: LLM tokenizer.\n        max_new_tokens: LLM output cap.\n        show_samples: Number of diagnostic printouts.\n    Returns:\n        prompts: list of string prompts sent to model.\n        responses: list of model outputs.\n    \"\"\"\n    SYS_PROMPT_DOI = \"\"\"\nYou are an expert at identifying research data citations in academic papers.\nYour task is to determine if a DOI citation in the given text refers specifically to research data, datasets, or data repositories.\nOnly respond with either a full normalized DOI URL starting with \"https://doi.org/\" or the word \"Irrelevant\" (without quotes).\nDo NOT include any other text or explanation.\nIf there is no DOI related to research data, respond with exactly \"Irrelevant\".\nIf multiple DOIs refer to research data, return any one of them.\n\"\"\"\n\n    llm_prompts = []\n    for article_id, context_window in chunks:\n        messages = [\n            {\"role\": \"system\", \"content\": SYS_PROMPT_DOI},\n            {\"role\": \"user\", \"content\": context_window}\n        ]\n        prompt = tokenizer.apply_chat_template(\n            messages,\n            add_generation_prompt=True,\n            tokenize=False,\n        )\n        llm_prompts.append(prompt)\n\n    responses = []\n    for prompt in tqdm(llm_prompts, desc=\"DOI LLM extraction\"):\n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n        with torch.no_grad():\n            output_ids = model.generate(\n                **inputs,\n                max_new_tokens=max_new_tokens,\n                do_sample=False,\n                pad_token_id=tokenizer.eos_token_id if tokenizer.eos_token_id is not None else tokenizer.pad_token_id\n            )\n        generated = output_ids[0][inputs[\"input_ids\"].shape[1]:]\n        response = tokenizer.decode(generated, skip_special_tokens=True).strip()\n        responses.append(response)\n\n    # Print a few sample outputs for inspection\n    for idx, ((article_id, context), resp) in enumerate(zip(chunks, responses[:show_samples])):\n        print(f\"\\nSAMPLE {idx+1}\")\n        print(\"Article:\", article_id)\n        print(\"Response:\", resp)\n        print(\"-\" * 40)\n\n    return llm_prompts, responses\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T19:11:46.756330Z","iopub.execute_input":"2025-08-05T19:11:46.756534Z","iopub.status.idle":"2025-08-05T19:11:46.764398Z","shell.execute_reply.started":"2025-08-05T19:11:46.756517Z","shell.execute_reply":"2025-08-05T19:11:46.763458Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# For training set\ntrain_prompts, train_llm_responses = run_llm_doi_extraction(train_chunks, model, tokenizer)\n\n# For validation set\nval_prompts, val_llm_responses = run_llm_doi_extraction(val_chunks, model, tokenizer)\n\n\n# --- Token length diagnostics ---\ndef check_prompt_token_lengths(prompts, tokenizer, label=\"\"):\n    prompt_lengths = [len(tokenizer(p)[\"input_ids\"]) for p in prompts]\n    print(f\"{label} prompts: token length stats - min {min(prompt_lengths)}, max {max(prompt_lengths)}, mean {sum(prompt_lengths)//len(prompt_lengths)}\")\n    print(f\"Model/tokenizer max input length: {tokenizer.model_max_length}\")\n    if max(prompt_lengths) > tokenizer.model_max_length:\n        print(f\"WARNING: Some {label} prompts exceed the model's max input length and will be truncated!\")\n    else:\n        print(f\"All {label} prompts fit within model input limits.\")\n\ncheck_prompt_token_lengths(train_prompts, tokenizer, label=\"Train\")\ncheck_prompt_token_lengths(val_prompts, tokenizer, label=\"Val\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-05T19:11:46.766794Z","iopub.execute_input":"2025-08-05T19:11:46.767293Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"DOI LLM extraction:   0%|          | 0/4901 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1957c7c906f4fe5a8147640e8d07bb0"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# --------- DIAGNOSTICS: Cell 2 (LLM Extraction -- Training Data) ---------\n\nresponses = train_llm_responses    # LLM responses for training data\nchunks = train_chunks              # Contexts/chunks used for LLM extraction\n\n# Irrelevant or empty responses\nirrelevant_count = sum((r.lower().strip() == \"irrelevant\" or r.strip() == \"\") for r in responses)\nprint(f\"[Cell 2 DIAGNOSTICS] (TRAIN) Irrelevant/empty LLM responses: {irrelevant_count} / {len(responses)} ({irrelevant_count/len(responses)*100:.1f} %)\")\n\n# Multiple DOIs in one response\nmulti_doi = sum('10.' in r and r.strip().count('10.') > 1 for r in responses)\nprint(f\"[Cell 2 DIAGNOSTICS] (TRAIN) LLM responses with >1 DOI string: {multi_doi} / {len(responses)}\")\n\n# Show example responses\nfor i in range(min(3, len(responses))):\n    print(f\"Article: {chunks[i][0]}\\nResponse: {responses[i][:200]}\\n---\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Clean LLM DOI Responses","metadata":{}},{"cell_type":"code","source":"# ------------- Cell 3: Clean LLM DOI Responses --------------\n\ndef clean_llm_doi_responses(\n    chunks,                # list of (article_id, context)\n    responses,             # list of LLM outputs, must match chunks order\n    preprint_prefixes = ['10.1101', '10.21203'],   # can be extended/changed if needed\n    show_head = 5\n):\n    \"\"\"\n    Cleans LLM DOI-extraction responses and returns a DataFrame of unique, relevant research data DOIs with context.\n\n    Args:\n        chunks: List of (article_id, context_window) tuples.\n        responses: List of model outputs (same order as chunks).\n        preprint_prefixes: DOIs starting with these prefixes are filtered out.\n        show_head: How many rows to show with print(df.head()).\n\n    Returns:\n        pd.DataFrame with columns: article_id, dataset_id, context_window\n    \"\"\"\n\n    # REGEX for DOI extraction (matches all plausible DOI forms)\n    doi_regex = re.compile(r\"(?:https?://(?:dx\\.)?doi\\.org/|doi:)?(10\\.\\d{4,12}/[\\w.\\-()/:;]+)\", re.I)\n\n    def normalize_doi(doi):\n        \"\"\"Return a normalized representation to compare article and dataset DOIs.\"\"\"\n        return doi.lower().replace('https://doi.org/','').replace('http://doi.org/','') \\\n            .replace('doi:','').replace('/','').replace('.','').replace('-','').replace('_','')\n\n    def is_preprint_doi(doi):\n        nd = normalize_doi(doi)\n        for prefix in preprint_prefixes:\n            if nd.startswith(prefix.replace('.','')):\n                return True\n        return False\n\n    extracted = []\n    for (article_id, context), resp in zip(chunks, responses):\n        if not resp or 'irrelevant' in resp.lower() or resp.strip() == '':\n            continue\n        dois_found = doi_regex.findall(resp)\n        for doi in dois_found:\n            doi_clean = doi.strip().rstrip('.,;:!?\"\\' \\t\\n\\r')\n            doi_url = f\"https://doi.org/{doi_clean}\"\n            extracted.append({\n                'article_id': article_id,\n                'dataset_id': doi_url,\n                'context_window': context\n            })\n\n    df_dois_llm = pd.DataFrame(extracted)\n    print(df_dois_llm.head(show_head))\n    print(f\"Extracted {len(df_dois_llm)} candidate research data DOIs with context.\")\n\n    before = len(df_dois_llm)\n    mask = df_dois_llm.apply(\n        lambda row: normalize_doi(row['dataset_id']) != normalize_doi(row['article_id']),\n        axis=1\n    )\n    df_dois_llm = df_dois_llm[mask].reset_index(drop=True)\n    after = len(df_dois_llm)\n    print(f\"[Cell 3 CLEAN] Removed {before-after} article self-DOI matches. Remaining: {after}\")\n\n    pre_before = len(df_dois_llm)\n    df_dois_llm = df_dois_llm[~df_dois_llm['dataset_id'].apply(is_preprint_doi)].reset_index(drop=True)\n    pre_after = len(df_dois_llm)\n    print(f\"[Cell 3 CLEAN] Removed {pre_before-pre_after} preprint DOIs. Remaining: {pre_after}\")\n\n    dedup_before = len(df_dois_llm)\n    df_dois_llm.drop_duplicates(subset=['article_id', 'dataset_id'], inplace=True, ignore_index=True)\n    print(f\"[Cell 3 CLEAN] Dropped {dedup_before-len(df_dois_llm)} duplicate (article_id, dataset_id) rows.\")\n\n    print(df_dois_llm['dataset_id'].value_counts().head())\n    print(f\"Final cleaned DOI extraction shape: {df_dois_llm.shape}\")\n\n    return df_dois_llm\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train_dois_llm = clean_llm_doi_responses(train_chunks, train_llm_responses)\ndf_val_dois_llm   = clean_llm_doi_responses(val_chunks, val_llm_responses)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LLM Classify Citations","metadata":{}},{"cell_type":"code","source":"import torch\nfrom tqdm.auto import tqdm\n\ndef classify_doi_contexts_with_llm(df_dois_llm, tokenizer, model, show_head=5):\n    \"\"\"\n    Classifies each (DOI, context_window) row as A/B/C with an LLM, attaches results to DataFrame.\n\n    Args:\n        df_dois_llm: DataFrame with columns ['article_id', 'dataset_id', 'context_window']\n        tokenizer:   Chat/instruction tokenizer for your LLM\n        model:       Your LLM model\n        show_head:   How many samples to print from classified DataFrame\n        \n    Returns:        New DataFrame with extra 'classification' column (A/B/C)\n    \"\"\"\n    SYS_PROMPT_CLASSIFY_DOI = \"\"\"\nClassify the following research data citation:\nA) Primary: Data was newly GENERATED or COLLECTED in THIS study (the paper in question).\nB) Secondary: Data is REUSED or TAKEN from a PUBLIC database/repository, previous study, or archive.\nC) None: Not research data.\n\nIf the data is from Zenodo, Dryad, PANGAEA, NCBI, EGA, SEANOE, or any public archive, or says \"available at ...\" or \"downloaded from ...\", it is almost always B.\n\nIf you are unsure, prefer B over A.\n\nEXAMPLES:\n\n- \"The raw sequencing data generated for this study has been deposited in NCBI SRA under accession SRX123456\" --> A\n- \"Data collected in this project are available at Zenodo DOI 10.5281/zenodo.1234567\" --> A\n- \"All measurement data from our experiments can be found in Dryad at doi:10.5061/dryad.XXXX\" --> A\n\n- \"We used the Dryad dataset in doi:10.5061/dryad.XXXX\" --> B\n- \"The reference database PANGAEA doi:10.1594/PANGAEA.123456 was used\" --> B\n- \"We analyzed transcriptome data from SRA accession SRX123456\" --> B\n- \"Supplementary Table S2\" --> C\n- \"The software package is available at github.com/myproject\" --> C\n\nRespond with ONLY one letter: A, B, or C. Do NOT explain your answer.\n\"\"\"\n\n    llm_classify_prompts = []\n    for _, row in df_dois_llm.iterrows():\n        messages = [\n            {\"role\": \"system\", \"content\": SYS_PROMPT_CLASSIFY_DOI},\n            {\"role\": \"user\", \"content\": f\"DOI: {row['dataset_id']}\\n\\nAcademic text/context:\\n{row['context_window']}\\n\\nOnly respond with a single letter: A, B, or C.\"}\n        ]\n        prompt = tokenizer.apply_chat_template(\n            messages,\n            add_generation_prompt=True,\n            tokenize=False,\n        )\n        llm_classify_prompts.append(prompt)\n\n    responses_class = []\n    for prompt in tqdm(llm_classify_prompts, desc=\"LLM A/B/C Classification\"):\n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n        with torch.no_grad():\n            output_ids = model.generate(\n                **inputs,\n                max_new_tokens=1,            # <---- CRUCIAL to get single-letter answer!\n                do_sample=False,\n                temperature=0.0,\n                pad_token_id=tokenizer.eos_token_id if tokenizer.eos_token_id is not None else tokenizer.pad_token_id\n            )\n        generated = output_ids[0][inputs[\"input_ids\"].shape[1]:]\n        resp = tokenizer.decode(generated, skip_special_tokens=True).strip().upper()\n        # Only accept A/B/C to avoid garbage output\n        if resp and resp[0] in \"ABC\":\n            responses_class.append(resp[0])\n        else:\n            responses_class.append(\"C\")\n    df_out = df_dois_llm.copy()\n    df_out['classification'] = responses_class\n\n    print(df_out['classification'].value_counts())\n    if show_head:\n        print(df_out.head(show_head))\n\n    return df_out\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For training:\ndf_train_dois_llm_classified = classify_doi_contexts_with_llm(df_train_dois_llm, tokenizer, model)\n\n# For validation:\ndf_val_dois_llm_classified = classify_doi_contexts_with_llm(df_val_dois_llm, tokenizer, model)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Clean and Map LLM Responses","metadata":{}},{"cell_type":"code","source":"def map_and_deduplicate_abc_df(df_classified):\n    \"\"\"\n    Map 'classification' column ('A','B',...) to 'Primary'/'Secondary',\n    drop Nones, and deduplicate by (article_id, dataset_id) favoring Primary.\n\n    Args:\n        df_classified: DataFrame with columns ['article_id', 'dataset_id', ..., 'classification']\n\n    Returns:\n        df_pred: filtered and deduplicated DataFrame, ready for submission\n    \"\"\"\n\n    def map_abc(x):\n        x = str(x).strip().upper()\n        if x == \"A\":\n            return \"Primary\"\n        if x == \"B\":\n            return \"Secondary\"\n        return None\n\n    df = df_classified.copy()\n    df['type'] = df['classification'].apply(map_abc)\n    df_pred = df[df['type'].notnull()].reset_index(drop=True)\n\n    # Favor Primary over Secondary for each (article_id, dataset_id) pair\n    df_pred = df_pred.sort_values(\n        by=[\"article_id\", \"dataset_id\", \"type\"],\n        key=lambda x: x.map({\"Primary\": 0, \"Secondary\": 1}) if x.name == \"type\" else x\n    )\n    df_pred = df_pred.drop_duplicates(subset=[\"article_id\", \"dataset_id\"], keep=\"first\").reset_index(drop=True)\n    return df_pred\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train_pred = map_and_deduplicate_abc_df(df_train_dois_llm_classified)\ndf_val_pred   = map_and_deduplicate_abc_df(df_val_dois_llm_classified)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Validation","metadata":{}},{"cell_type":"code","source":"# Remove '.pdf' if present in article_id\ndf_train_pred['article_id'] = df_train_pred['article_id'].astype(str).str.replace('.pdf','', regex=False)\ndf_val_pred['article_id'] = df_val_pred['article_id'].astype(str).str.replace('.pdf','', regex=False)\ndf_train_labels['article_id'] = df_train_labels['article_id'].astype(str).str.replace('.pdf','', regex=False)\ndf_val_labels['article_id'] = df_val_labels['article_id'].astype(str).str.replace('.pdf','', regex=False)\n\n\nprint(\"Train labels articles:\", len(df_train_labels['article_id'].unique()))\nprint(\"Val labels articles:\", len(df_val_labels['article_id'].unique()))\n\nprint(\"Unique train pred articles:\", df_train_pred['article_id'].nunique())\nprint(\"Unique train label articles:\", df_train_labels['article_id'].nunique())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_f1_scores(df_pred, df_labels, name=''):\n    \"\"\"\n    Compute TP, FP, FN, and F1 score for a set of predictions vs. labels.\n    Prints and returns stats.\n\n    Args:\n        df_pred: DataFrame with columns ['article_id', 'dataset_id', 'type']\n        df_labels: DataFrame (ground truth) with columns ['article_id', 'dataset_id', 'type']\n        name: Optional string to identify output (e.g. 'TRAIN', 'VAL')\n\n    Returns:\n        dict: {'tp': ..., 'fp': ..., 'fn': ..., 'f1': ...}\n    \"\"\"\n\n    def f1_score(tp, fp, fn):\n        return 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) != 0 else 0.0\n\n    # Exclude \"Missing\" from labels\n    df_labels_eval = df_labels[df_labels['type'] != 'Missing'].reset_index(drop=True)\n\n    # Hits: intersection where article_id, dataset_id, and type all match\n    hits_df = df_labels_eval.merge(df_pred, on=[\"article_id\", \"dataset_id\", \"type\"])\n\n    tp = hits_df.shape[0]\n    fp = df_pred.shape[0] - tp\n    fn = df_labels_eval.shape[0] - tp\n    f1 = f1_score(tp, fp, fn)\n\n    print(f\"\\n===== {name} RESULTS =====\")\n    print(\"TP:\", tp)\n    print(\"FP:\", fp)\n    print(\"FN:\", fn)\n    print(\"F1 Score:\", round(f1, 3))\n\n    return {'tp': tp, 'fp': fp, 'fn': fn, 'f1': f1}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training set\ntrain_scores = compute_f1_scores(df_train_pred, df_train_labels, name=\"TRAINING\")\n\n# Validation set\nval_scores = compute_f1_scores(df_val_pred, df_val_labels, name=\"VALIDATION\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training scores:\", train_scores)\nprint(\"Validation scores:\", val_scores)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}